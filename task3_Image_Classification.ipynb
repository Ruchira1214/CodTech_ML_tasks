{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/X3HxSGYejLeaecrUNjkQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ruchira1214/CodTech_ML_tasks/blob/main/task3_Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue8kyVgUVScV",
        "outputId": "3a9f1ce4-2e1d-43b0-8c86-e30478746cfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: False\n",
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Cell 1 — Check GPU\n",
        "import torch\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"Device:\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2 — Install sklearn (runs fast)\n",
        "!pip install -q scikit-learn"
      ],
      "metadata": {
        "id": "qVuMM9B46lTY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3 — Fast PyTorch CNN training on CIFAR-10 (paste whole cell)\n",
        "import os, time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BATCH_SIZE = 128\n",
        "NUM_EPOCHS = 5       # small for quick run\n",
        "LR = 1e-3\n",
        "SAVE_PATH = \"/content/cnn_model.pth\"\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "# --- Simple (fast) CNN ---\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),  # 32x16x16\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2), # 64x8x8\n",
        "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2) # 128x4x4\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128*4*4, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# --- Data ---\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914,0.4822,0.4465),(0.247,0.243,0.261))\n",
        "])\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914,0.4822,0.4465),(0.247,0.243,0.261))\n",
        "])\n",
        "\n",
        "train_set = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform_train)\n",
        "test_set  = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform_test)\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
        "test_loader  = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "classes = train_set.classes\n",
        "\n",
        "# --- Model / Loss / Opt ---\n",
        "model = SimpleCNN(num_classes=len(classes)).to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "# --- Training loop ---\n",
        "def train_one_epoch(model, loader, opt, criterion):\n",
        "    model.train()\n",
        "    running_loss = 0.0; correct = 0; total = 0\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "        opt.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        running_loss += loss.item()*images.size(0)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        correct += (preds==labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "    return running_loss/total, correct/total\n",
        "\n",
        "def eval_model(model, loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    preds_all, labels_all = [], []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()*images.size(0)\n",
        "            preds_all.append(outputs.argmax(dim=1).cpu().numpy())\n",
        "            labels_all.append(labels.cpu().numpy())\n",
        "    preds_all = np.concatenate(preds_all)\n",
        "    labels_all = np.concatenate(labels_all)\n",
        "    return running_loss/len(labels_all), preds_all, labels_all\n",
        "\n",
        "start_time = time.time()\n",
        "best_acc = 0.0\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    t0 = time.time()\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n",
        "    val_loss, preds, labels = eval_model(model, test_loader, criterion)\n",
        "    val_acc = (preds==labels).mean()\n",
        "    epoch_time = time.time()-t0\n",
        "    print(f\"Epoch {epoch}/{NUM_EPOCHS} — {epoch_time:.1f}s  Train loss: {train_loss:.4f} Acc: {train_acc:.4f}  |  Test loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save(model.state_dict(), SAVE_PATH)\n",
        "print(f\"\\nDone in {(time.time()-start_time)/60:.2f} minutes. Best test acc: {best_acc:.4f}\")\n",
        "# --- Final metrics ---\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "_, preds, labels = eval_model(model, test_loader, criterion)\n",
        "print(\"\\nClassification report:\\n\", classification_report(labels, preds, target_names=classes, zero_division=0, digits=4))\n",
        "print(\"Confusion matrix shape:\", confusion_matrix(labels, preds).shape)\n",
        "print(f\"\\nSaved best model to: {SAVE_PATH}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5U3XfPBe6x4z",
        "outputId": "56a16e86-79d1-4ec7-ea74-be9cef02b3c7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 42.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 — 122.7s  Train loss: 1.6357 Acc: 0.3958  |  Test loss: 1.2450 Acc: 0.5533\n",
            "Epoch 2/5 — 118.9s  Train loss: 1.2468 Acc: 0.5503  |  Test loss: 0.9849 Acc: 0.6510\n",
            "Epoch 3/5 — 118.1s  Train loss: 1.0746 Acc: 0.6191  |  Test loss: 0.8793 Acc: 0.6915\n",
            "Epoch 4/5 — 118.0s  Train loss: 0.9578 Acc: 0.6639  |  Test loss: 0.8214 Acc: 0.7159\n",
            "Epoch 5/5 — 117.5s  Train loss: 0.8914 Acc: 0.6892  |  Test loss: 0.7621 Acc: 0.7318\n",
            "\n",
            "Done in 9.92 minutes. Best test acc: 0.7318\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    airplane     0.7459    0.7750    0.7602      1000\n",
            "  automobile     0.8801    0.8440    0.8617      1000\n",
            "        bird     0.5866    0.6500    0.6167      1000\n",
            "         cat     0.5979    0.4490    0.5128      1000\n",
            "        deer     0.7367    0.6490    0.6901      1000\n",
            "         dog     0.6084    0.7100    0.6553      1000\n",
            "        frog     0.8643    0.7260    0.7891      1000\n",
            "       horse     0.6982    0.8260    0.7568      1000\n",
            "        ship     0.8702    0.8180    0.8433      1000\n",
            "       truck     0.7694    0.8710    0.8171      1000\n",
            "\n",
            "    accuracy                         0.7318     10000\n",
            "   macro avg     0.7358    0.7318    0.7303     10000\n",
            "weighted avg     0.7358    0.7318    0.7303     10000\n",
            "\n",
            "Confusion matrix shape: (10, 10)\n",
            "\n",
            "Saved best model to: /content/cnn_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4 — Download the saved model to your computer (runs in Colab)\n",
        "from google.colab import files\n",
        "files.download(\"/content/cnn_model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "vs6sAYwm601i",
        "outputId": "c1b12c44-5721-41ad-9b0e-edea183e8412"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1a58ec7e-44f6-4925-8d07-4582f9c7cd32\", \"cnn_model.pth\", 2485861)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bqawdEbQ9sHF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}